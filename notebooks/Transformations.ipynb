{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib_resources import open_binary, open_text\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.realpath(os.path.join('..', 'tests', 'data'))\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pose3d_utils.skeleton import MPI3D_SKELETON_DESC, CANONICAL_SKELETON_DESC\n",
    "\n",
    "group_colours = dict(centre='magenta', left='blue', right='red')\n",
    "\n",
    "def plot_skeleton_on_axes3d(skel, skel_desc, ax: Axes3D, invert=True, alpha=1.0):\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "\n",
    "    # NOTE: y and z axes are swapped\n",
    "    xs = skel.narrow(-1, 0, 1).numpy()\n",
    "    ys = skel.narrow(-1, 2, 1).numpy()\n",
    "    zs = skel.narrow(-1, 1, 1).numpy()\n",
    "\n",
    "    # Correct aspect ratio (https://stackoverflow.com/a/21765085)\n",
    "    max_range = np.array([\n",
    "        xs.max() - xs.min(), ys.max() - ys.min(), zs.max() - zs.min()\n",
    "    ]).max() / 2.0\n",
    "    mid_x = (xs.max() + xs.min()) * 0.5\n",
    "    mid_y = (ys.max() + ys.min()) * 0.5\n",
    "    mid_z = (zs.max() + zs.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    if invert:\n",
    "        ax.invert_zaxis()\n",
    "\n",
    "    # Set starting view\n",
    "    ax.view_init(elev=20, azim=-100)\n",
    "\n",
    "    for joint_id, joint in enumerate(skel):\n",
    "        meta = skel_desc.get_joint_metadata(joint_id)\n",
    "        color = group_colours[meta['group']]\n",
    "        parent = skel[meta['parent']]\n",
    "        offset = parent - joint\n",
    "        ax.quiver(\n",
    "            [joint[0]], [joint[2]], [joint[1]],\n",
    "            [offset[0]], [offset[2]], [offset[1]],\n",
    "            color=color,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "    ax.scatter(xs, ys, zs, color='grey', alpha=alpha)\n",
    "\n",
    "def visualise_example(camera, image, points, skel_desc=MPI3D_SKELETON_DESC, save=None):\n",
    "    \"\"\"Show the image and projected points in a matplotlib figure.\"\"\"\n",
    "    points2d = camera.project_cartesian(torch.as_tensor(points))\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    for joint_id, (x, y) in enumerate(np.array(points2d)):\n",
    "        meta = skel_desc.get_joint_metadata(joint_id)\n",
    "        color = group_colours[meta['group']]\n",
    "        parent = points2d[meta['parent']]\n",
    "        ax1.plot([x, parent[0]], [y, parent[1]], color=color)\n",
    "    ax1.scatter(points2d[:, 0], points2d[:, 1], color='grey', s=12)\n",
    "    ax1.set_xlim([0, image.width - 1])\n",
    "    ax1.set_ylim([image.height - 1, 0])\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    plot_skeleton_on_axes3d(torch.as_tensor(points), skel_desc, ax2)\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pose3d_utils.camera import CameraIntrinsics\n",
    "import torch\n",
    "\n",
    "img = PIL.Image.open(os.path.join(data_dir, 'example01_image.jpg'))\n",
    "\n",
    "with open(os.path.join(data_dir, 'example01_camera.json'), 'r') as f:\n",
    "    camera_params = json.load(f)\n",
    "\n",
    "camera = CameraIntrinsics(torch.tensor(camera_params['intrinsic'])[:3])\n",
    "\n",
    "with open(os.path.join(data_dir, 'example01_univ_annot3.txt'), 'r') as f:\n",
    "    univ_annot3 = np.loadtxt(f)\n",
    "\n",
    "visualise_example(camera, img, univ_annot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose3d_utils.transformers import TransformerContext\n",
    "import pose3d_utils.transforms as transforms\n",
    "\n",
    "points2d = camera.project_cartesian(torch.as_tensor(univ_annot3))\n",
    "cx, cy = points2d[MPI3D_SKELETON_DESC.root_joint_id].tolist()\n",
    "\n",
    "transforms = [\n",
    "    transforms.PanImage(camera.x_0 - cx, camera.y_0 - cy),\n",
    "    transforms.RotateImage(30),\n",
    "    transforms.ZoomImage(2.0),\n",
    "    transforms.HorizontalFlip(do_flip=True, flip_indices=MPI3D_SKELETON_DESC.hflip_indices),\n",
    "]\n",
    "\n",
    "for i in range(len(transforms) + 1):\n",
    "    ctx = TransformerContext(camera, img.width, img.height, msaa=1)\n",
    "    for transform in transforms[:i]:\n",
    "        ctx.add(transform)\n",
    "    tuple1 = (camera, img, torch.as_tensor(univ_annot3))\n",
    "    tuple2 = ctx.transform(*tuple1)\n",
    "    if i > 0:\n",
    "        print(transforms[i - 1])\n",
    "    # visualise_example(*tuple2, save='Transformations_{:02d}.svg'.format(i))\n",
    "    visualise_example(*tuple2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
